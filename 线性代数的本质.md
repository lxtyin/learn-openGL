本篇学习自 [3b1b 线性代数的本质](https://www.bilibili.com/video/BV1ys411472E?p=7&spm_id_from=pageDriver&vd_source=f3bceb9b12c557f0a9cdb5ac0d26fee6)



##### 向量

可看做点，这里统一竖着写（列向量）。

##### 线性变换

对空间中的每个点作变换后，轴保持平行等距，原点不变。

##### 矩阵

表达一种一种线性变换，这里我们将向量竖着写，向量左乘一个矩阵即应用一个变换。矩阵中一列的意义是：一个基向量变换后的新位置，因为是线性变换，故直接将基向量代换掉，即可计算向量变换后的位置。

##### 非方阵

非方阵同样代表着线性变换，但它还涉及维数的改变。

非方阵中的列同样代表着变换后的新基向量位置，但这些新的基向量可能少维或者多维。

回忆矩阵乘法中，$n\times m$ 的矩阵只能和 $m$ 维的向量相乘，它将 $m$ 维向量的每个基代换为一个新的 $n$ 维向量，这样得到的新向量便从 $m$ 维变到了 $n$ 维。

注意，向量本身只是一个箭头或者点，其维度信息是我们赋予的，简单地加一维数字将向量变高维并不会不合理。



##### 行列式

等于相应矩阵对应的变换下，**空间内任意物体缩放的比例。**若行列式为负，则空间发生翻转，行列式为0，则变换将压缩至少一个维度。

我们已经知道，将矩阵看做线性变换后，其每一列都可以看做一个基向量变换后的位置。故矩阵对应行列式的值，即该矩阵各列向量拼出来的空间大小(二维的平行四边形面积，三维的平行六面体体积等）。

##### 矩阵的秩

按此矩阵变换后，空间的维度，不降维的变换矩阵满秩。

##### 逆矩阵

显然，只有不降维（满秩）的变换才可逆。

##### 线性方程组

线性方程组可以看做对一个由未知量组成的向量 $x$，施加以变换矩阵 $A$ 后得到一个已知向量 $y$，即 $Ax=y$。如果这个矩阵可逆，则可以反推出所有未知量，否则要么无解（变换降维了，$y$ 在变化后的维度之外），要么有无穷多解（$y$ 恰好在变换后的维度之内）。

##### 列空间

即变换后的空间，叫列空间即矩阵每一列（变换后每个基）的张成空间。**秩精确定义为列空间的维数**。$y$ 在列空间内，方程才有解。

##### 零空间

使 $Ax=0$ 成立的 $x$ 的集合，即变换后会变为零向量的向量集，对于满秩矩阵，零空间中只有零向量。

##### 点积

点积在数值上等于两个向量对应位相乘之和，几何上等于一个向量投影到另一个向量上之后模相乘。

这两者可以得以联系，是因为可以将点积的两个向量，一个看做向量 $[a,b]^T$，另一个转置后看做线性变换 $[x, y]$。这个显然这是一个将二维降至一维的线性变换，它的含义恰恰就是将向量投影到一维空间。

更进一步，我们会发现**每一种二维到一维的线性变换都与一个某个向量一一对应**（转置即可）。应用此变换等价于与该向量点乘。

##### 叉积

通常在三维空间下讨论叉积，我们都知道的是：两个向量叉积得到一个与它们都垂直的向量，模长等于两向量张成的平行四边形面积，方向取决于右手定则，叉积公式即将 $i,j,k$ 与两向量放入一个行列式。

叉积的几何意义很明朗，但问题在于为什么计算会和行列式相关。

考虑三个向量 $u,v,m$，把它们放入一个三阶行列式，结果显然为张成的平行六面体体积。

如果我们固定其中两个，任选第三个，这就相当于是一个变换函数，输入向量 $[x,y,z]^T$，得到一个标量输出：
$$
f\begin{pmatrix}
x\\
y\\
z\\
\end{pmatrix}=
\begin{vmatrix}
x,v_1,m_1\\
y,v_2,m_2\\
z,v_3,m_3
\end{vmatrix}
$$
可以证明，这同样是一个三维到一维的**线性变换**。既然是线性变换，可以表示为矩阵 $P\times [x,y,z]^T$，其中 $P$ 为1x3的降维变换矩阵。

根据点积中提到的对偶性，这个变换等价于 $P^T\cdot [x,y,z]^T$

什么样的 $P^T$ 点乘任意一个向量，都能得到它与 $v,m$ 组成的平行六面体体积？

画图，根据点积的投影计算方式，容易发现，$P^T$ 模长为 $v,m$ 平行四边形面积，方向与它们都垂直，正是我们需要叉积结果。

那么要计算这个 $P^T$，可以用一点运算小技巧，取 $(x,y,z)$ 为单位向量，并且把它们的方向 $(i,j,k)$ 写出来，就能化标量为矢量了。
$$
P^T\cdot [i,j,k]^T=
\begin{vmatrix}
i,v_1,m_1\\
j,v_2,m_2\\
k,v_3,m_3
\end{vmatrix}
$$

##### 基变换

基变换的逻辑容易理解，但方向很容易搞反，弄清**数值和位置**

如：坐标系 $A$ 的基向量为 $[0,1],[1,0]$，坐标系 $B$ 的基向量为 $b1,b2$，根据之前的知识，我们可以将其看做变换矩阵 $[b1,b2]$，$A$ 坐标表示下的一个向量经过此矩阵变换，即变换到了 $B$ 坐标表示下**相同数值**的一个向量。

但上述过程并没有什么意义，更多情况下我们希望对于同一个向量，在 $A$ 坐标系表示和 $B$ 坐标系表示下进行转换，而非变换向量本身，这才是所谓的基变换。

考虑 $A$ 坐标系下向量 $va$，先变换到 $B$ 坐标系下，数值不变，再经过逆矩阵变回来，数值改变，位置变回来，故此向量 $v_a$ 在 $B$ 坐标系下的表示即为：$[b1,b2]^{-1}\times v_a$

##### 相似矩阵

另一个常见的操作是：向量 $v_a$ 在 $A$ 坐标系下表示，我希望以 $B$ 坐标系为参考进行某种变换 $T$，但仍在 $A$ 系下表示，设 $P=[b1,b2]$ 为 $B$ 的基向量。

很简单：先改为在 $B$ 坐标系下表示，然后变换，然后再变回 $A$ 系。

该变化等价于左乘 $PTP^{-1}$，这就是相似矩阵，它意味着在一个坐标系下，参考另一个坐标系进行变换。

##### 特征值/特征向量

按某矩阵进行变换后，会发现有些向量只是缩放，并没有离开原来的直线

这些向量便是矩阵的特征向量，其缩放比例即为对应的特征值。
